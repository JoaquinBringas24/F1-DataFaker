digraph {
	graph [size="19.349999999999998,19.349999999999998"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2637964579504 [label="
 (32, 1)" fillcolor=darkolivegreen1]
	2633106444768 [label=RoundBackward0]
	2633106442608 -> 2633106444768
	2633106442608 [label=SigmoidBackward0]
	2633106445824 -> 2633106442608
	2633106445824 [label=AddmmBackward0]
	2633106445632 -> 2633106445824
	2637922461712 [label="layers.16.bias
 (1)" fillcolor=lightblue]
	2637922461712 -> 2633106445632
	2633106445632 [label=AccumulateGrad]
	2633106445872 -> 2633106445824
	2633106445872 [label=LeakyReluBackward0]
	2633106453744 -> 2633106445872
	2633106453744 [label=AddmmBackward0]
	2633106444480 -> 2633106453744
	2637922454704 [label="layers.14.bias
 (2)" fillcolor=lightblue]
	2637922454704 -> 2633106444480
	2633106444480 [label=AccumulateGrad]
	2633106452160 -> 2633106453744
	2633106452160 [label=LeakyReluBackward0]
	2633106444528 -> 2633106452160
	2633106444528 [label=AddmmBackward0]
	2633106445440 -> 2633106444528
	2637922456912 [label="layers.12.bias
 (4)" fillcolor=lightblue]
	2637922456912 -> 2633106445440
	2633106445440 [label=AccumulateGrad]
	2633106444960 -> 2633106444528
	2633106444960 [label=LeakyReluBackward0]
	2633106443760 -> 2633106444960
	2633106443760 [label=AddmmBackward0]
	2633106449856 -> 2633106443760
	2637922460080 [label="layers.10.bias
 (8)" fillcolor=lightblue]
	2637922460080 -> 2633106449856
	2633106449856 [label=AccumulateGrad]
	2633106449952 -> 2633106443760
	2633106449952 [label=LeakyReluBackward0]
	2633106449664 -> 2633106449952
	2633106449664 [label=AddmmBackward0]
	2633106446736 -> 2633106449664
	2637922460464 [label="layers.8.bias
 (16)" fillcolor=lightblue]
	2637922460464 -> 2633106446736
	2633106446736 [label=AccumulateGrad]
	2633106449616 -> 2633106449664
	2633106449616 [label=LeakyReluBackward0]
	2633106442512 -> 2633106449616
	2633106442512 [label=AddmmBackward0]
	2633106452400 -> 2633106442512
	2637922457008 [label="layers.6.bias
 (32)" fillcolor=lightblue]
	2637922457008 -> 2633106452400
	2633106452400 [label=AccumulateGrad]
	2633106443664 -> 2633106442512
	2633106443664 [label=LeakyReluBackward0]
	2633106454128 -> 2633106443664
	2633106454128 [label=AddmmBackward0]
	2633106442560 -> 2633106454128
	2636856309424 [label="layers.4.bias
 (64)" fillcolor=lightblue]
	2636856309424 -> 2633106442560
	2633106442560 [label=AccumulateGrad]
	2633106446400 -> 2633106454128
	2633106446400 [label=LeakyReluBackward0]
	2633106449280 -> 2633106446400
	2633106449280 [label=AddmmBackward0]
	2633106442416 -> 2633106449280
	2630599868592 [label="layers.2.bias
 (128)" fillcolor=lightblue]
	2630599868592 -> 2633106442416
	2633106442416 [label=AccumulateGrad]
	2633106450144 -> 2633106449280
	2633106450144 [label=LeakyReluBackward0]
	2633106453072 -> 2633106450144
	2633106453072 [label=AddmmBackward0]
	2633106452592 -> 2633106453072
	2630599871952 [label="layers.0.bias
 (128)" fillcolor=lightblue]
	2630599871952 -> 2633106452592
	2633106452592 [label=AccumulateGrad]
	2633106452688 -> 2633106453072
	2633106452688 [label=TBackward0]
	2633106452544 -> 2633106452688
	2641331056816 [label="layers.0.weight
 (128, 223)" fillcolor=lightblue]
	2641331056816 -> 2633106452544
	2633106452544 [label=AccumulateGrad]
	2633106449808 -> 2633106449280
	2633106449808 [label=TBackward0]
	2633106453024 -> 2633106449808
	2637871836592 [label="layers.2.weight
 (128, 128)" fillcolor=lightblue]
	2637871836592 -> 2633106453024
	2633106453024 [label=AccumulateGrad]
	2633106447456 -> 2633106454128
	2633106447456 [label=TBackward0]
	2633106445344 -> 2633106447456
	2636856309328 [label="layers.4.weight
 (64, 128)" fillcolor=lightblue]
	2636856309328 -> 2633106445344
	2633106445344 [label=AccumulateGrad]
	2633106442656 -> 2633106442512
	2633106442656 [label=TBackward0]
	2633106453168 -> 2633106442656
	2636856309616 [label="layers.6.weight
 (32, 64)" fillcolor=lightblue]
	2636856309616 -> 2633106453168
	2633106453168 [label=AccumulateGrad]
	2633106449712 -> 2633106449664
	2633106449712 [label=TBackward0]
	2633106450672 -> 2633106449712
	2637922461136 [label="layers.8.weight
 (16, 32)" fillcolor=lightblue]
	2637922461136 -> 2633106450672
	2633106450672 [label=AccumulateGrad]
	2633106443808 -> 2633106443760
	2633106443808 [label=TBackward0]
	2633106452976 -> 2633106443808
	2637922455664 [label="layers.10.weight
 (8, 16)" fillcolor=lightblue]
	2637922455664 -> 2633106452976
	2633106452976 [label=AccumulateGrad]
	2633106445056 -> 2633106444528
	2633106445056 [label=TBackward0]
	2633106442464 -> 2633106445056
	2637922456432 [label="layers.12.weight
 (4, 8)" fillcolor=lightblue]
	2637922456432 -> 2633106442464
	2633106442464 [label=AccumulateGrad]
	2633106446016 -> 2633106453744
	2633106446016 [label=TBackward0]
	2633106446832 -> 2633106446016
	2637922455856 [label="layers.14.weight
 (2, 4)" fillcolor=lightblue]
	2637922455856 -> 2633106446832
	2633106446832 [label=AccumulateGrad]
	2633106444624 -> 2633106445824
	2633106444624 [label=TBackward0]
	2633106443904 -> 2633106444624
	2637922459984 [label="layers.16.weight
 (1, 2)" fillcolor=lightblue]
	2637922459984 -> 2633106443904
	2633106443904 [label=AccumulateGrad]
	2633106444768 -> 2637964579504
}
